\documentclass{article}

\usepackage[english]{babel}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{ragged2e}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{listings} % To show C++ structs as context
\usepackage{xcolor}
\usepackage{caption}

\lstdefinestyle{cppstyle}{
    language=C++,
    backgroundcolor=\color{gray!10},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    commentstyle=\color{green!50!black},
    morekeywords={MoveType, Move, Solution, DistanceMatrix},
    tabsize=2,
    breaklines=true,
    frame=tb,
    framerule=0pt
}

\title{Evolutionary Computation - Assignment 4}
\author{
  Patryk Janiak\\
  \texttt{156053}
  \and
  Marek Seget\\
  \texttt{156042}
}

\begin{document}
\maketitle

\section{Problem description}
We are given three columns of integers with a row for each node. The first two columns contain x
and y coordinates of the node positions in a plane. The third column contains node costs. The goal is
to select exactly 50\% of the nodes (if the number of nodes is odd we round the number of nodes to
be selected up) and form a Hamiltonian cycle (closed path) through this set of nodes such that the
sum of the total length of the path plus the total cost of the selected nodes is minimized.

\input{algorithms.tex}

\section{Results}

\input{scores.tex}

\input{times.tex}

\subsection{TSPA.csv}

\input{TSPA.tex}

\subsection{TSPB.csv}

\input{TSPB.tex}

\newpage

\section{Conclusions}

Two local search algorithms were implemented and compared: `ls\_steepest\_edges\_random` and `ls\_improving\_moves\_list\_random`. Both algorithms start with a random initial solution.

The `ls\_steepest\_edges\_random` algorithm explores the entire neighborhood of 2-opt moves and inter-route swaps in a steepest descent manner. In contrast, the `ls\_improving\_moves\_list\_random` algorithm uses a list of moves and picks the first one that improves the solution. This is intended to speed up the search process.

From the results, we can observe that `ls\_steepest\_edges\_random` consistently finds better solutions than `ls\_improving\_moves\_list\_random` for both TSPA and TSPB instances. This suggests that the greedy nature of the improving moves list approach, while faster, may be too aggressive and cause the search to get stuck in local optima and miss promising regions of the solution space.

The `ls\_improving\_moves\_list\_random` is faster than the `ls\_steepest\_edges\_random` method. This is expected, as it doesn't have to evaluate all possible moves in each iteration.

In conclusion, for this particular problem, the trade-off between search speed and solution quality favors the more exhaustive `ls\_steepest\_edges\_random` approach. While the improving moves list strategy offers a significant speed-up, it comes at the cost of solution quality.

Link to the source code:

\url{https://github.com/markopolo139/Evolutionary-computation-put/tree/main/ass4}

The best solutions were checked with the provided solution checker.

\end{document}
